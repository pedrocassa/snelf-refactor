def run():
    # -*- coding: utf-8 -*-
    """pre_proc_medicamentos_augmented.ipynb

    Automatically generated by Colaboratory.

    Original file is located at
        https://colab.research.google.com/drive/1zoemqrhcCDbaEghB6StJkKAKjzHVZ6J9
    """

    import sys
    sys.path.append('..')

    """## Exemplo de uso da lib Extractor"""

    from _libs.extractor import Extractor as xtc

    descricao = 'HYNALGIN DIPIRONA 500MG/ML INJETÁVEL 5ML C/100'
    xtc.extract(descricao)

    """## Config

    ### Imports
    """

    import pandas as pd
    import numpy as np
    import re
    import nltk
    # nltk.download('stopwords')
    # nltk.download('punkt')

    from nltk.tokenize import word_tokenize
    from nltk.corpus import stopwords
    from string import punctuation

    from _libs.extractor import Extractor as xtc

    """### Stopwords"""

    # loading new_stopwords
    with open('_pre_processamento/custom_stopwords.txt') as f:
        data = f.read()
    new_stopwords = data.split()

    # updating stopwords with new_stopwords
    stopwords = set(stopwords.words('portuguese') + list(punctuation))
    print(len(stopwords))

    custom_stopwords = stopwords.copy()
    custom_stopwords.update(new_stopwords)
    print(len(custom_stopwords))

    """### Functions"""

    def clean_desc(words, desc):
        subs = [sub.strip() for sub in re.split('‹|–|::|-|\|', desc)]  # split in substrings
        new_desc = ''

        for sub in subs:
            for word in words:
                if word in sub.split():
                    new_desc += ' {}'.format(sub)
                    break

        return new_desc.strip()  # return without extra initial space

    def get_words(text):
        return [w for w in word_tokenize(text) if w.lower() not in custom_stopwords]

    def remove_blank(terms):
        return [re.sub('\s', '', t) if t is not None else t for t in terms]

    # clean_desc Example
    desc = 'GLICOSE 5% CX C/40 FRASCOS X 250ML'
    deriv = 'SORO DE GLICOSE 5% - EUROFARMA | DENTAL CREMER PRODUTOS'

    print(desc)
    print(clean_desc(get_words(desc), deriv))

    # Extractor example
    produto = 'ESPIRONOLACTONA 100MG CX C/30 CP'
    principio_ativo, concentracao, forma_farmaceutica, quantidade = xtc.extract(produto)

    print(' ---- '.join([principio_ativo, concentracao, forma_farmaceutica, quantidade]))

    """### Path"""

    data_path = 'datasets/medicamentos/augmented/'
    data_file = 'medicamentos_aumentado.csv'

    """## Parse

    ### Removendo ";" que não representa o separador do CSV
    """

    def custom_replace(desc):
        start = desc.find(';') + 1
        end = desc.rfind(';')
        return desc[:start] + desc[start:end].replace(';', ',') + desc[end:]

    src = '{}{}'.format(data_path, data_file)
    target = '{}{}_mod.csv'.format(data_path, data_file[:-4])

    buff = 300
    content = ''

    with open(src, 'r', encoding='utf-8') as fs:
        with open(target, 'w', encoding='utf-8') as ft:
            ft.write(fs.readline())  # header
            lines = fs.readlines(buff)
            while lines:
                for line in lines:
                    content += custom_replace(line)
                ft.write(content)
                content = ''
                lines = fs.readlines(buff)

    """## Pré-processamento

    #### Loading
    """

    # header => ['cod', 'descricao', 'ean']
    data_file = 'medicamentos_aumentado_mod.csv'
    src = '{}{}'.format(data_path, data_file)

    df = pd.read_csv(src, dtype={0: int, 1: str, 2: str}, sep=';')
    df.shape

    """#### Removendo substrings com base nas palavras da descrição original

    #### Removendo registros com base nos termos principais
    """

    idxs = list()
    removed = list()

    # iterate over dataframe
    for index, row in df.iterrows():
        if row['cod'] == 1:
            original_words = get_words(row['descricao'])  # get non stopwords
            _, conc, _, qtd = xtc.extract(row['descricao'])  # get principal terms
            conc, qtd = remove_blank([conc, qtd])
            master_idx = index
            continue

        new_desc = clean_desc(original_words, row['descricao'])  # remove irrelevant substrings
        if not new_desc:
            idxs.append(index)  # storage index for future drop
            removed.append([master_idx, index])
            continue

        _, new_conc, _, new_qtd = xtc.extract(new_desc)  # get principal terms
        new_conc, new_qtd = remove_blank([new_conc, new_qtd])

        if conc == new_conc and qtd == new_qtd:
            df.at[index, 'descricao'] = new_desc  # replace descricao with cleaned new_desc
        else:
            idxs.append(index)  # storage index for future drop
            removed.append([master_idx, index])

    """### Removed"""

    df_removed = pd.DataFrame(removed, columns=['master_idx', 'removed_idx'])
    df_removed.head()

    df_grouped = df_removed.groupby('master_idx')['removed_idx'].apply(list).reset_index()
    df_grouped.head()

    pd.set_option('display.max_colwidth', None)

    # master, removed = df_grouped.loc[4000].values
    # indexes = [master] + removed
    # df.loc[indexes][['cod', 'descricao']]

    # DEBUG

    descricao = 'CLORIDRATO DE MEMANTINA 10MG C\60 C1'
    derivado = 'CLORIDRATO DE MEMANTINA 10MG 60 COMPRIMIDOS EUROFARMA | DROGA'

    original_words = get_words(descricao)  # get non stopwords
    _, conc, _, qtd = xtc.extract(descricao)  # get principal terms
    conc, qtd = remove_blank([conc, qtd])
    print(original_words)
    print(conc, qtd, '\n')

    new_desc = clean_desc(original_words, derivado)  # remove irrelevant substrings
    _, new_conc, _, new_qtd = xtc.extract(new_desc)  # get principal terms
    new_conc, new_qtd = remove_blank([new_conc, new_qtd])
    print(new_desc)
    print(new_conc, new_qtd, '\n')

    if conc == new_conc and qtd == new_qtd:
        print('igual')

    """### Removing"""

    df.drop(idxs, inplace=True)
    df.dropna(inplace=True)
    df.drop_duplicates(inplace=True)
    df.shape

    """#### Removendo registros  com os termos
    * BULA
    * PREÇO
    * BARATO
    """

    cond1 = df['cod'] == 1
    # or (
    cond2 = df['cod'] == 3
    # and
    cond3 = ~df['descricao'].str.contains('BULA|PREÇO|BARATO', regex=True)
    # )

    df = df[cond1 | (cond2 & cond3)]
    df.shape

    """#### Removendo os termos <font color='red'>(devem ser removidos nesta ordem)</font>
    * EM MERCADO LIVRE BRASIL
    * EM MERCADO LIVRE
    * NO MERCADO LIVRE BRASIL
    * NO MERCADO LIVRE
    * COMPRAR EM ILHA DENTAL
    * COMPRAR EM AGROFORTE
    * COMPRAR EM FARMA PRATA
    * ONDE COMPRAR (apenas no início do registro)
    * COMPRAR
    * ENCONTRE (apenas no início do registro)

    #### Após as remoções acima, remover os registros com os termos
    * ENCONTRE
    """

    pattern1 = r'(?i)(em|no)?\s+mercado\s+livre\s*(brasil)?'
    pattern2 = r'(?i)comprar em (ilha dental|agroforte|farma prata)'
    pattern3 = r'(?i)(onde)?\s*comprar'
    pattern4 = r'(?i)^encontre'

    replaces = {pattern1: '',
                pattern2: '',
                pattern3: '',
                pattern4: '', }

    df.replace(replaces, regex=True, inplace=True)

    cond1 = df['cod'] == 1
    cond2 = ~df['descricao'].str.contains('ENCONTRE')
    df = df[cond1 | cond2]
    df.shape

    pattern = r'(?i)mercado livre|comprar|encontre'
    df[df['descricao'].str.contains(pattern)]

    pattern = r'(?i)oferta'
    df[df['descricao'].str.contains(pattern)].shape

    df.head()

    # after removing, strip again
    df['descricao'] = df['descricao'].str.strip()

    start = 5056
    end = start + 20
    cod = df['cod'].tolist()[start:end]
    desc = df['descricao'].tolist()[start:end]
    lista = list(zip(cod, desc))
    for cod, desc in lista:
        if cod == 3:
            tab = '\t'
            br = ''
        else:
            tab = ''
            br = '\n'
            original_words = [w for w in desc if len(w) > 2]
        print('{}{}{}'.format(br, tab, desc))

    """### Gravando em arquivo"""

    data_file = 'medicamentos_aumentado_preproc.csv'
    df.to_csv('{}{}'.format(data_path, data_file),
              sep=';',
              header=df.columns,
              index=False,
              encoding='utf-8')